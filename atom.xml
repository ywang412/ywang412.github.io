<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://ywang412.github.io</id>
    <title>Yu&apos;s Github</title>
    <updated>2019-08-18T01:54:43.952Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://ywang412.github.io"/>
    <link rel="self" href="https://ywang412.github.io/atom.xml"/>
    <subtitle>Java by day, Scala by night</subtitle>
    <logo>https://ywang412.github.io/images/avatar.png</logo>
    <icon>https://ywang412.github.io/favicon.ico</icon>
    <rights>All rights reserved 2019, Yu&apos;s Github</rights>
    <entry>
        <title type="html"><![CDATA[Examples of System Design]]></title>
        <id>https://ywang412.github.io/post/system-design</id>
        <link href="https://ywang412.github.io/post/system-design">
        </link>
        <updated>2019-08-04T22:48:51.000Z</updated>
        <content type="html"><![CDATA[<p>byte 1 byte -128 to 127.
short 2 bytes -32,768 to 32,767.
int 4 bytes -2,147,483,648 to 2,147,483,647.
long 8 bytes -9,223,372,036,854,775,808 to 9,223,372,036,854,775,807.</p>
<p><strong>Designing TinyURL</strong></p>
<p>Encoding actual URL
We can compute a unique hash (e.g., MD5 or SHA256, etc.) of the given URL. The hash can then be encoded for displaying. This encoding could be base36 ([a-z ,0-9]) or base62 ([A-Z, a-z, 0-9]) and if we add ‘-’ and ‘.’ we can use base64 encoding. A reasonable question would be, what should be the length of the short key? 6, 8 or 10 characters.</p>
<p>Using base64 encoding, a 6 letter long key would result in 64^6 = ~68.7 billion possible strings
Using base64 encoding, an 8 letter long key would result in 64^8 = ~281 trillion possible strings</p>
<p>With 68.7B unique strings, let’s assume six letter keys would suffice for our system.</p>
<p>If we use the MD5 algorithm as our hash function, it’ll produce a 128-bit hash value. After base64 encoding, we’ll get a string having more than 21 characters (since each base64 character encodes 6 bits of the hash value). Since we only have space for 8 characters per short key, how will we choose our key then? We can take the first 6 (or 8) letters for the key. This could result in key duplication though, upon which we can choose some other characters out of the encoding string or swap some characters.</p>
<p>What are different issues with our solution? We have the following couple of problems with our encoding scheme:</p>
<p>If multiple users enter the same URL, they can get the same shortened URL, which is not acceptable.
What if parts of the URL are URL-encoded? e.g., http://www.educative.io/distributed.php?id=design, and http://www.educative.io/distributed.php%3Fid%3Ddesign are identical except for the URL encoding.
Workaround for the issues: We can append an increasing sequence number to each input URL to make it unique, and then generate a hash of it. We don’t need to store this sequence number in the databases, though. Possible problems with this approach could be an ever-increasing sequence number. Can it overflow? Appending an increasing sequence number will also impact the performance of the service.</p>
<p>Another solution could be to append user id (which should be unique) to the input URL. However, if the user has not signed in, we would have to ask the user to choose a uniqueness key. Even after this, if we have a conflict, we have to keep generating a key until we get a unique one.</p>
<p><img src="https://ywang412.github.io/post-images/1565756686530.png" alt="">
<img src="https://ywang412.github.io/post-images/1565754688299.png" alt=""></p>
<p><strong>Designing Pastebin</strong></p>
<p><img src="https://ywang412.github.io/post-images/1565757376688.png" alt="">
<img src="https://ywang412.github.io/post-images/1565756747081.png" alt=""></p>
<p><strong>Design Instagram</strong></p>
<p><img src="https://ywang412.github.io/post-images/1565757489241.png" alt="">
a. Partitioning based on UserID Let’s assume we shard based on the ‘UserID’ so that we can keep all photos of a user on the same shard. If one DB shard is 1TB, we will need four shards to store 3.7TB of data. Let’s assume for better performance and scalability we keep 10 shards.</p>
<p>So we’ll find the shard number by UserID % 10 and then store the data there. To uniquely identify any photo in our system, we can append shard number with each PhotoID.</p>
<p>How can we generate PhotoIDs? Each DB shard can have its own auto-increment sequence for PhotoIDs and since we will append ShardID with each PhotoID, it will make it unique throughout our system.</p>
<p>What are the different issues with this partitioning scheme?</p>
<p>How would we handle hot users? Several people follow such hot users and a lot of other people see any photo they upload.
Some users will have a lot of photos compared to others, thus making a non-uniform distribution of storage.
What if we cannot store all pictures of a user on one shard? If we distribute photos of a user onto multiple shards will it cause higher latencies?
Storing all photos of a user on one shard can cause issues like unavailability of all of the user’s data if that shard is down or higher latency if it is serving high load etc.
b. Partitioning based on PhotoID If we can generate unique PhotoIDs first and then find a shard number through “PhotoID % 10”, the above problems will have been solved. We would not need to append ShardID with PhotoID in this case as PhotoID will itself be unique throughout the system.</p>
<p>How can we generate PhotoIDs? Here we cannot have an auto-incrementing sequence in each shard to define PhotoID because we need to know PhotoID first to find the shard where it will be stored. One solution could be that we dedicate a separate database instance to generate auto-incrementing IDs. If our PhotoID can fit into 64 bits, we can define a table containing only a 64 bit ID field. So whenever we would like to add a photo in our system, we can insert a new row in this table and take that ID to be our PhotoID of the new photo.</p>
<p>Wouldn’t this key generating DB be a single point of failure? Yes, it would be. A workaround for that could be defining two such databases with one generating even numbered IDs and the other odd numbered. For the MySQL, the following script can define such sequences:</p>
<pre><code>KeyGeneratingServer1:
auto-increment-increment = 2
auto-increment-offset = 1 
KeyGeneratingServer2:
auto-increment-increment = 2
auto-increment-offset = 2
</code></pre>
<p>We can put a load balancer in front of both of these databases to round robin between them and to deal with downtime. Both these servers could be out of sync with one generating more keys than the other, but this will not cause any issue in our system. We can extend this design by defining separate ID tables for Users, Photo-Comments, or other objects present in our system.</p>
<p>Alternately, we can implement a ‘key’ generation scheme similar to what we have discussed in Designing a URL Shortening service like TinyURL.</p>
<p><img src="https://ywang412.github.io/post-images/1565757623378.png" alt=""></p>
<p><strong>Design Dropbox</strong></p>
<p>The metadata Database should be storing information about following objects:</p>
<p>Chunks
Files
User
Devices
Workspace (sync folders)</p>
<p><img src="https://ywang412.github.io/post-images/1565757709181.png" alt="">
<img src="https://ywang412.github.io/post-images/1565757739488.png" alt=""></p>
<p><strong>Designing Messenger</strong></p>
<p><img src="https://ywang412.github.io/post-images/1566064813925.png" alt="">
<img src="https://ywang412.github.io/post-images/1566064820748.png" alt=""></p>
<p><strong>Designing Twitter</strong></p>
<p><img src="https://ywang412.github.io/post-images/1566067729831.png" alt="">
<img src="https://ywang412.github.io/post-images/1566067734387.png" alt=""></p>
<p><strong>Designing Youtube</strong></p>
<p>At a high-level we would need the following components:</p>
<p>Processing Queue: Each uploaded video will be pushed to a processing queue to be de-queued later for encoding, thumbnail generation, and storage.
Encoder: To encode each uploaded video into multiple formats.
Thumbnails generator: To generate a few thumbnails for each video.
Video and Thumbnail storage: To store video and thumbnail files in some distributed file storage.
User Database: To store user’s information, e.g., name, email, address, etc.
Video metadata storage: A metadata database to store all the information about videos like title, file path in the system, uploading user, total views, likes, dislikes, etc. It will also be used to store all the video comments.</p>
<p><img src="https://ywang412.github.io/post-images/1566070090262.png" alt=""></p>
<p><strong>Design Rate Limiter</strong></p>
<p><img src="https://ywang412.github.io/post-images/1566091665748.png" alt=""></p>
<p>fixed window
<img src="https://ywang412.github.io/post-images/1566091776264.png" alt="">
sliding wondow
<img src="https://ywang412.github.io/post-images/1566091784751.png" alt="">
bucket counter
if we have an hourly rate limit we can keep a count for each minute and calculate the sum of all counters in the past hour when we receive a new request to calculate the throttling limit</p>
<p><strong>Design Typeahead Suggestion</strong></p>
<p>Should we have case insensitive trie? For simplicity and search use-case, let’s assume our data is case insensitive.</p>
<p>How to find top suggestion? Now that we can find all the terms for a given prefix, how can we find the top 10 terms for the given prefix? One simple solution could be to store the count of searches that terminated at each node, e.g., if users have searched about ‘CAPTAIN’ 100 times and ‘CAPTION’ 500 times, we can store this number with the last character of the phrase. Now if the user types ‘CAP’ we know the top most searched word under the prefix ‘CAP’ is ‘CAPTION’. So, to find the top suggestions for a given prefix, we can traverse the sub-tree under it.</p>
<p>Given a prefix, how much time will it take to traverse its sub-tree? Given the amount of data we need to index, we should expect a huge tree. Even traversing a sub-tree would take really long, e.g., the phrase ‘system design interview questions’ is 30 levels deep. Since we have very strict latency requirements we do need to improve the efficiency of our solution.</p>
<p>Can we store top suggestions with each node? This can surely speed up our searches but will require a lot of extra storage. We can store top 10 suggestions at each node that we can return to the user. We have to bear the big increase in our storage capacity to achieve the required efficiency.</p>
<p>We can optimize our storage by storing only references of the terminal nodes rather than storing the entire phrase. To find the suggested terms we need to traverse back using the parent reference from the terminal node. We will also need to store the frequency with each reference to keep track of top suggestions.</p>
<p>How would we build this trie? We can efficiently build our trie bottom up. Each parent node will recursively call all the child nodes to calculate their top suggestions and their counts. Parent nodes will combine top suggestions from all of their children to determine their top suggestions.</p>
<p>How to update the trie? Assuming five billion searches every day, which would give us approximately 60K queries per second. If we try to update our trie for every query it’ll be extremely resource intensive and this can hamper our read requests, too. One solution to handle this could be to update our trie offline after a certain interval.</p>
<p>As the new queries come in we can log them and also track their frequencies. Either we can log every query or do sampling and log every 1000th query. For example, if we don’t want to show a term which is searched for less than 1000 times, it’s safe to log every 1000th searched term.</p>
<p>We can have a Map-Reduce (MR) set-up to process all the logging data periodically say every hour. These MR jobs will calculate frequencies of all searched terms in the past hour. We can then update our trie with this new data. We can take the current snapshot of the trie and update it with all the new terms and their frequencies. We should do this offline as we don’t want our read queries to be blocked by update trie requests. We can have two options:</p>
<p>We can make a copy of the trie on each server to update it offline. Once done we can switch to start using it and discard the old one.
Another option is we can have a master-slave configuration for each trie server. We can update slave while the master is serving traffic. Once the update is complete, we can make the slave our new master. We can later update our old master, which can then start serving traffic, too.
How can we update the frequencies of typeahead suggestions? Since we are storing frequencies of our typeahead suggestions with each node, we need to update them too! We can update only differences in frequencies rather than recounting all search terms from scratch. If we’re keeping count of all the terms searched in last 10 days, we’ll need to subtract the counts from the time period no longer included and add the counts for the new time period being included. We can add and subtract frequencies based on Exponential Moving Average (EMA) of each term. In EMA, we give more weight to the latest data. It’s also known as the exponentially weighted moving average.</p>
<p>After inserting a new term in the trie, we’ll go to the terminal node of the phrase and increase its frequency. Since we’re storing the top 10 queries in each node, it is possible that this particular search term jumped into the top 10 queries of a few other nodes. So, we need to update the top 10 queries of those nodes then. We have to traverse back from the node to all the way up to the root. For every parent, we check if the current query is part of the top 10. If so, we update the corresponding frequency. If not, we check if the current query’s frequency is high enough to be a part of the top 10. If so, we insert this new term and remove the term with the lowest frequency.</p>
<p>How can we remove a term from the trie? Let's say we have to remove a term from the trie because of some legal issue or hate or piracy etc. We can completely remove such terms from the trie when the regular update happens, meanwhile, we can add a filtering layer on each server which will remove any such term before sending them to users.</p>
<p>What could be different ranking criteria for suggestions? In addition to a simple count, for terms ranking, we have to consider other factors too, e.g., freshness, user location, language, demographics, personal history etc.</p>
<p>Typeahead Client
We can perform the following optimizations on the client side to improve user’s experience:</p>
<p>The client should only try hitting the server if the user has not pressed any key for 50ms.
If the user is constantly typing, the client can cancel the in-progress requests.
Initially, the client can wait until the user enters a couple of characters.
Clients can pre-fetch some data from the server to save future requests.
Clients can store the recent history of suggestions locally. Recent history has a very high rate of being reused.
Establishing an early connection with the server turns out to be one of the most important factors. As soon as the user opens the search engine website, the client can open a connection with the server. So when a user types in the first character, the client doesn’t waste time in establishing the connection.
The server can push some part of their cache to CDNs and Internet Service Providers (ISPs) for efficiency.</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[DP summary]]></title>
        <id>https://ywang412.github.io/post/dp-summary</id>
        <link href="https://ywang412.github.io/post/dp-summary">
        </link>
        <updated>2019-08-02T07:37:53.000Z</updated>
        <content type="html"><![CDATA[<ol start="375">
<li>Guess Number Higher or Lower II</li>
<li>Best Time to Buy and Sell Stock IV</li>
</ol>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Monotonic Stack]]></title>
        <id>https://ywang412.github.io/post/monotonic-stack</id>
        <link href="https://ywang412.github.io/post/monotonic-stack">
        </link>
        <updated>2019-07-30T02:40:22.000Z</updated>
        <content type="html"><![CDATA[<p><strong>739. Daily Temperatures and 496. Next Greater Element I</strong></p>
<pre><code>class Solution {
    public int[] dailyTemperatures(int[] temperatures) {
        Stack&lt;Integer&gt; stack = new Stack&lt;&gt;();
        int[] ret = new int[temperatures.length];
        for(int i = 0; i &lt; temperatures.length; i++) {
            while(!stack.isEmpty() &amp;&amp; temperatures[i] &gt; temperatures[stack.peek()]) {
                int idx = stack.pop();
                ret[idx] = i - idx;
            }
            stack.push(i);
        }
        return ret;
    }
}
</code></pre>
<p><strong>Largest Rectangle in Histogram</strong></p>
<pre><code>public class Solution {
    public int largestRectangleArea(int[] height) {
        int len = height.length;
        Stack&lt;Integer&gt; s = new Stack&lt;Integer&gt;();
        int maxArea = 0;
        int i = 0;
        while(i &lt;= len){
            int h = (i == len ? 0 : height[i]);
            if(s.isEmpty() || h &gt;= height[s.peek()]){
                s.push(i);
                i++;
            }else{
                int tp = s.pop();
                maxArea = Math.max(maxArea, height[tp] * (s.isEmpty() ? i : i - 1 - s.peek()));
                 
            }
        }
        return maxArea;
    }
}
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Quick sort, quick select and merge sort]]></title>
        <id>https://ywang412.github.io/post/quick-sort-quick-select-and-merge-sort</id>
        <link href="https://ywang412.github.io/post/quick-sort-quick-select-and-merge-sort">
        </link>
        <updated>2019-07-28T00:09:43.000Z</updated>
        <content type="html"><![CDATA[<p><strong>215. Kth Largest Element in an Array</strong></p>
<pre><code>class Solution {
    public int findKthLargest(int[] nums, int k) {
        return quickSelectK(nums, 0, nums.length - 1, nums.length - k);
    }
    
    public int quickSelectK(int[] nums, int start, int end, int k) { 
        
        int pivot = nums[start];
        int i = start;
        int j = end;
        while (i &lt; j) { 
            while (i &lt; end &amp;&amp; nums[i] &lt;= pivot) i++;
            while (j &gt; start &amp;&amp; nums[j] &gt;= pivot) j--; 
            if (i &lt; j) {
                int temp = nums[i];
                nums[i] = nums[j];
                nums[j] = temp;
            }   
        } 
        nums[start] = nums[j];
        nums[j] = pivot;
        if (j == k) return nums[j];
        else if (j &lt; k) return quickSelectK(nums, j + 1, end, k);
        else return quickSelectK(nums, start, j, k);
    } 
}
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Java JUC (java.util.concurrent) 5 - ThreadPool and ThreadLocal]]></title>
        <id>https://ywang412.github.io/post/java-juc-javautilconcurrent-5-threadpool-and-threadlocal</id>
        <link href="https://ywang412.github.io/post/java-juc-javautilconcurrent-5-threadpool-and-threadlocal">
        </link>
        <updated>2019-07-07T01:19:02.000Z</updated>
        <content type="html"><![CDATA[<p>Java use Thread Pool pattern to save resources in a multithreaded application, and also to contain the parallelism in certain predefined limits. It controls several re-used threads for executing these tasks.</p>
<pre><code>ExecutorService executorService = Executors.newCachedThreadPool();
for (int i = 0; i &lt; 10; i++) {
		final int index = i;
		executorService.execute(new Runnable() {
				@Override
				public void run() {
						log.info(&quot;task:{}&quot;, index);
				}
		});
}
executorService.shutdown();
</code></pre>
<p>There are several pre-defined threadpool for various scenarios.</p>
<pre><code>ExecutorService executorService = Executors.newFixedThreadPool(3);
ExecutorService executorService = Executors.newSingleThreadExecutor();
ScheduledExecutorService executorService = Executors.newScheduledThreadPool(1);
</code></pre>
<p>The TheadLocal construct allows us to store data that will be accessible only by a specific thread.</p>
<pre><code>private final static ThreadLocal&lt;Long&gt; requestHolder = new ThreadLocal&lt;&gt;();
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Java JUC (java.util.concurrent) 4 - Lock]]></title>
        <id>https://ywang412.github.io/post/java-juc-javautilconcurrent-2-lock</id>
        <link href="https://ywang412.github.io/post/java-juc-javautilconcurrent-2-lock">
        </link>
        <updated>2019-07-03T17:07:58.000Z</updated>
        <content type="html"><![CDATA[<p>Compare to <code>synchronized</code> keyword, Locks support various methods for finer grained control thus are more expressive than <code>synchronized</code>.</p>
<p>Since <code>synchronized</code> keyword create lock implicitly, one can convert the  <code>synchronized</code> keyword to ReentrantLock.</p>
<pre><code>private synchronized static void add() {
        count++;
}
</code></pre>
<pre><code>private final static Lock lock = new ReentrantLock();
private static void add() {
		lock.lock();
		try {
				count++;
		} finally {
				lock.unlock();
		}
}
</code></pre>
<p>Therefore, it is possible for both <code>synchronized</code> and Lock to introduce the well-know deadlock problem like below.</p>
<pre><code>public class DeadLock implements Runnable {
    public int flag = 1;
    //静态对象是类的所有对象共享的
    private static Object o1 = new Object(), o2 = new Object();

    @Override
    public void run() {
        log.info(&quot;flag:{}&quot;, flag);
        if (flag == 1) {
            synchronized (o1) {
                try {
                    Thread.sleep(500);
                } catch (Exception e) {
                    e.printStackTrace();
                }
                synchronized (o2) {
                    log.info(&quot;1&quot;);
                }
            }
        }
        if (flag == 0) {
            synchronized (o2) {
                try {
                    Thread.sleep(500);
                } catch (Exception e) {
                    e.printStackTrace();
                }
                synchronized (o1) {
                    log.info(&quot;0&quot;);
                }
            }
        }
    }

    public static void main(String[] args) {
        DeadLock td1 = new DeadLock();
        DeadLock td2 = new DeadLock();
        td1.flag = 1;
        td2.flag = 0;
        //td1,td2都处于可执行状态，但JVM线程调度先执行哪个线程是不确定的。
        //td2的run()可能在td1的run()之前运行
        new Thread(td1).start();
        new Thread(td2).start();
    }
}
</code></pre>
<p>The <code>synchronized</code> keyword provides a simplified model while Lock offers more APIs such as ReentrantReadWriteLock and Condition. The interface ReadWriteLock specifies a pair of locks for read and write access. This can improve performance and throughput in cases where write-accesses are much less frequent.</p>
<pre><code>private final Map&lt;String, Data&gt; map = new TreeMap&lt;&gt;();

private final ReentrantReadWriteLock lock = new ReentrantReadWriteLock();
private final Lock readLock = lock.readLock();
private final Lock writeLock = lock.writeLock();

public Data get(String key) {
		readLock.lock();
		try {
				return map.get(key);
		} finally {
				readLock.unlock();
		}
}

public Data put(String key, Data value) {
		writeLock.lock();
		try {
				return map.put(key, value);
		} finally {
				writeLock.unlock();
		}
}
</code></pre>
<p><code>Condition.signalAll()</code> is a very important API in consumer-producer model.</p>
<pre><code>public static void main(String[] args) {
		ReentrantLock reentrantLock = new ReentrantLock();
		Condition condition = reentrantLock.newCondition();

		new Thread(() -&gt; {
				try {
						reentrantLock.lock();
						log.info(&quot;wait signal&quot;); // 1
						condition.await();
				} catch (InterruptedException e) {
						e.printStackTrace();
				}
				log.info(&quot;get signal&quot;); // 4
				reentrantLock.unlock();
		}).start();

		new Thread(() -&gt; {
				reentrantLock.lock();
				log.info(&quot;get lock&quot;); // 2
				try {
						Thread.sleep(3000);
				} catch (InterruptedException e) {
						e.printStackTrace();
				}
				condition.signalAll();
				log.info(&quot;send signal ~ &quot;); // 3
				reentrantLock.unlock();
		}).start();
}
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Contributing to Scala zio, a github open source project]]></title>
        <id>https://ywang412.github.io/post/contributing-to-a-scala-zio-a-github-open-source-project</id>
        <link href="https://ywang412.github.io/post/contributing-to-a-scala-zio-a-github-open-source-project">
        </link>
        <updated>2019-06-23T04:54:56.000Z</updated>
        <content type="html"><![CDATA[<p>I've hoped to contribute to open source project on github to be a part of the open source community and become a better developer. Today my two pull requests to a high profile scala repository, zio, got approved and I am very excited. The friendly and encouraging github community brought me a great experience.</p>
<p>These are the two pull requests that I made.</p>
<p>https://github.com/zio/zio/pull/1109
and
https://github.com/zio/zio/pull/1106</p>
<p>The first one is to deprecate a FiberLocal class.
<img src="https://ywang412.github.io/post-images/1561874927019.png" alt="">
The second one is to fix a bug resulting from different Windows/Linux file seperator.
<img src="https://ywang412.github.io/post-images/1561874992932.png" alt=""></p>
<p>The zio scala repository is very well maintained with decent test coverage and CD/CI pipeline. Thanks to the project maintainers for their huge efforts.</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Java JUC (java.util.concurrent) 3 - Synchronized and Synchronized Container]]></title>
        <id>https://ywang412.github.io/post/java-juc-javautilconcurrent-3-synchronzied-and-synchronzied-container</id>
        <link href="https://ywang412.github.io/post/java-juc-javautilconcurrent-3-synchronzied-and-synchronzied-container">
        </link>
        <updated>2019-05-14T11:31:10.000Z</updated>
        <content type="html"><![CDATA[<p><code>Synchronized</code> keyword bounds monitor to an object and has made concurrency programing simple. It can be added to method or object to achieve object level synchronization. It can also modify static method or class for class level synchronization.</p>
<pre><code>// 修饰一个代码块
public void test1(int j) {
		synchronized (this) {
				for (int i = 0; i &lt; 10; i++) {
						log.info(&quot;test1 {} - {}&quot;, j, i);
				}
		}
}

// 修饰一个方法
public synchronized void test2(int j) {
		for (int i = 0; i &lt; 10; i++) {
				log.info(&quot;test2 {} - {}&quot;, j, i);
		}
}

public static void main(String[] args) {
		SynchronizedExample1 example1 = new SynchronizedExample1();
		SynchronizedExample1 example2 = new SynchronizedExample1();
		ExecutorService executorService = Executors.newCachedThreadPool();
		executorService.execute(() -&gt; {
				example1.test2(1);
		});
		executorService.execute(() -&gt; {
				example2.test2(2);
		});
}
</code></pre>
<pre><code>// 修饰一个类
public static void test1(int j) {
		synchronized (SynchronizedExample2.class) {
				for (int i = 0; i &lt; 10; i++) {
						log.info(&quot;test1 {} - {}&quot;, j, i);
				}
		}
}

// 修饰一个静态方法
public static synchronized void test2(int j) {
		for (int i = 0; i &lt; 10; i++) {
				log.info(&quot;test2 {} - {}&quot;, j, i);
		}
}

public static void main(String[] args) {
		SynchronizedExample2 example1 = new SynchronizedExample2();
		SynchronizedExample2 example2 = new SynchronizedExample2();
		ExecutorService executorService = Executors.newCachedThreadPool();
		executorService.execute(() -&gt; {
				example1.test1(1);
		});
		executorService.execute(() -&gt; {
				example2.test1(2);
		});
}
</code></pre>
<p>Java provide several thread safe synchronized containers out of the box.</p>
<pre><code>private static List&lt;Integer&gt; list = Collections.synchronizedList(Lists.newArrayList());
private static Set&lt;Integer&gt; set = Collections.synchronizedSet(Sets.newHashSet());
private static Map&lt;Integer, Integer&gt; map = Collections.synchronizedMap(new HashMap&lt;&gt;());
private static Map&lt;Integer, Integer&gt; map = new Hashtable&lt;&gt;();
private static List&lt;Integer&gt; list = new Vector&lt;&gt;();
</code></pre>
<p>Java and Guava also provide several immutable containers out of the box.</p>
<pre><code>private static Map&lt;Integer, Integer&gt; map = Maps.newHashMap();
static {
		map.put(1, 2);
		map.put(3, 4);
		map.put(5, 6);
		map = Collections.unmodifiableMap(map);
}
</code></pre>
<pre><code>import com.google.common.collect.ImmutableList;
import com.google.common.collect.ImmutableMap;
import com.google.common.collect.ImmutableSet;
private final static ImmutableList&lt;Integer&gt; list = ImmutableList.of(1, 2, 3);
private final static ImmutableSet set = ImmutableSet.copyOf(list);
private final static ImmutableMap&lt;Integer, Integer&gt; map = ImmutableMap.of(1, 2, 3, 4);
private final static ImmutableMap&lt;Integer, Integer&gt; map2 = ImmutableMap.&lt;Integer, Integer&gt;builder()
				.put(1, 2).put(3, 4).put(5, 6).build();
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Java JUC (java.util.concurrent) 2 - Atomic Variables and Concurrent Collection]]></title>
        <id>https://ywang412.github.io/post/java-juc-javautilconcurrent-2-atomic-variables</id>
        <link href="https://ywang412.github.io/post/java-juc-javautilconcurrent-2-atomic-variables">
        </link>
        <updated>2019-04-25T01:22:48.000Z</updated>
        <content type="html"><![CDATA[<p>Atomic varaibles are important parts of java concurrency API. It allows multiple threads safely access the same variables. The java.util.concurrent.atomic classes heavily used compare-and-swap (CAS) technique. CAS happens at CPU instruction level and is much more light weighted than synchronizing through locks or <code>synchronized</code> key word.</p>
<p>AtomicInteger, AtomicLong, LongAdder, AtomicBoolean, and AtomicReference<Integer> are some of the most used Atomic classes.</p>
<p><strong>AtomicInteger</strong></p>
<pre><code>// 请求总数
public static int clientTotal = 5000;
// 同时并发执行的线程数
public static int threadTotal = 200;
public static AtomicInteger count = new AtomicInteger(0);

public static void main(String[] args) throws Exception {
		ExecutorService executorService = Executors.newCachedThreadPool();
		final Semaphore semaphore = new Semaphore(threadTotal);
		final CountDownLatch countDownLatch = new CountDownLatch(clientTotal);
		for (int i = 0; i &lt; clientTotal ; i++) {
				executorService.execute(() -&gt; {
						try {
								semaphore.acquire();
								add();
								semaphore.release();
						} catch (Exception e) {
								log.error(&quot;exception&quot;, e);
						}
						countDownLatch.countDown();
				});
		}
		countDownLatch.await();
		executorService.shutdown();
		log.info(&quot;count:{}&quot;, count.get());
}

private static void add() {
		count.incrementAndGet();
		// count.getAndIncrement();
}
</code></pre>
<p>Another way to acheive correct counting result like above is <code>synchronized</code> keyword.</p>
<pre><code>// 请求总数
public static int clientTotal = 5000;
// 同时并发执行的线程数
public static int threadTotal = 200;
public static int count = 0;

public static void main(String[] args) throws Exception {
		ExecutorService executorService = Executors.newCachedThreadPool();
		final Semaphore semaphore = new Semaphore(threadTotal);
		final CountDownLatch countDownLatch = new CountDownLatch(clientTotal);
		for (int i = 0; i &lt; clientTotal ; i++) {
				executorService.execute(() -&gt; {
						try {
								semaphore.acquire();
								add();
								semaphore.release();
						} catch (Exception e) {
								log.error(&quot;exception&quot;, e);
						}
						countDownLatch.countDown();
				});
		}
		countDownLatch.await();
		executorService.shutdown();
		log.info(&quot;count:{}&quot;, count);
}

private synchronized static void add() {
		count++;
}
</code></pre>
<p>However, volatile keyword as in <code>public static volatile int count = 0;</code> will not be able to ensure threadsafety to due CPU instruction reorder.</p>
<p>ConcurrentHashMap, ConcurrentSkipListMap, ConcurrentSkipListSet, CopyOnWriteArrayList, CopyOnWriteArraySet are some typical concurrency collection classes in Java 8.</p>
<p><strong>CopyOnWriteArrayList</strong></p>
<pre><code>// 请求总数
public static int clientTotal = 5000;
// 同时并发执行的线程数
public static int threadTotal = 200;
private static List&lt;Integer&gt; list = new CopyOnWriteArrayList&lt;&gt;();

public static void main(String[] args) throws Exception {
		ExecutorService executorService = Executors.newCachedThreadPool();
		final Semaphore semaphore = new Semaphore(threadTotal);
		final CountDownLatch countDownLatch = new CountDownLatch(clientTotal);
		for (int i = 0; i &lt; clientTotal; i++) {
				final int count = i;
				executorService.execute(() -&gt; {
						try {
								semaphore.acquire();
								update(count);
								semaphore.release();
						} catch (Exception e) {
								log.error(&quot;exception&quot;, e);
						}
						countDownLatch.countDown();
				});
		}
		countDownLatch.await();
		executorService.shutdown();
		log.info(&quot;size:{}&quot;, list.size());
}

private static void update(int i) {
		list.add(i);
}
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Java JUC (java.util.concurrent) 1 - AQS：AbstractQueuedSynchronizer]]></title>
        <id>https://ywang412.github.io/post/java-juc-javautilconcurrent-1-aqsabstractqueuedsynchronizer</id>
        <link href="https://ywang412.github.io/post/java-juc-javautilconcurrent-1-aqsabstractqueuedsynchronizer">
        </link>
        <updated>2019-04-09T19:02:16.000Z</updated>
        <content type="html"><![CDATA[<p>AbstractQueuedSynchronizer lays the foundation of java JUC programming. Concurrency classes are extensively using Sync class which extends from AQS as shown below.</p>
<p><img src="https://ywang412.github.io/post-images/1562476011734.png" alt=""></p>
<p>Some example code snippets of CountDownLatch, CyclicBarrier, Semaphore, ForkJoinTask, and FutureTask are explained here.</p>
<p><strong>CountDownLatch</strong></p>
<pre><code>public static void main(String[] args) throws Exception {
		ExecutorService exec = Executors.newCachedThreadPool();
		final CountDownLatch countDownLatch = new CountDownLatch(threadCount);
		for (int i = 0; i &lt; threadCount; i++) {
				final int threadNum = i;
				exec.execute(() -&gt; {
						try {
								test(threadNum);
						} catch (Exception e) {
								log.error(&quot;exception&quot;, e);
						} finally {
								countDownLatch.countDown();
						}
				});
		}
		countDownLatch.await(10, TimeUnit.MILLISECONDS);
		log.info(&quot;finish&quot;);
		exec.shutdown();
}

private static void test(int threadNum) throws Exception {
		Thread.sleep(100);
		log.info(&quot;{}&quot;, threadNum);
}
</code></pre>
<p><strong>CyclicBarrier</strong></p>
<pre><code>private static CyclicBarrier barrier = new CyclicBarrier(5);

public static void main(String[] args) throws Exception {
		ExecutorService executor = Executors.newCachedThreadPool();
		for (int i = 0; i &lt; 10; i++) {
				final int threadNum = i;
				Thread.sleep(1000);
				executor.execute(() -&gt; {
						try {
								race(threadNum);
						} catch (Exception e) {
								log.error(&quot;exception&quot;, e);
						}
				});
		}
		executor.shutdown();
}

private static void race(int threadNum) throws Exception {
		Thread.sleep(1000);
		log.info(&quot;{} is ready&quot;, threadNum);
		barrier.await();
		log.info(&quot;{} continue&quot;, threadNum);
}
</code></pre>
<p><strong>Semaphore</strong></p>
<pre><code>ExecutorService exec = Executors.newCachedThreadPool();
final Semaphore semaphore = new Semaphore(3);

for (int i = 0; i &lt; threadCount; i++) {
		final int threadNum = i;
		exec.execute(() -&gt; {
				try {
						if (semaphore.tryAcquire(5000, TimeUnit.MILLISECONDS)) { // 尝试获取一个许可
								test(threadNum);
								semaphore.release(); // 释放一个许可
						}
				} catch (Exception e) {
						log.error(&quot;exception&quot;, e);
				}
		});
}
exec.shutdown();
}

private static void test(int threadNum) throws Exception {
log.info(&quot;{}&quot;, threadNum);
Thread.sleep(1000);
}
</code></pre>
<p><strong>ForkJoinTask</strong></p>
<pre><code>public class ForkJoinTaskExample extends RecursiveTask&lt;Integer&gt; {

    public static final int threshold = 2;
    private int start;
    private int end;

    public ForkJoinTaskExample(int start, int end) {
        this.start = start;
        this.end = end;
    }

    @Override
    protected Integer compute() {
        int sum = 0;

        //如果任务足够小就计算任务
        boolean canCompute = (end - start) &lt;= threshold;
        if (canCompute) {
            for (int i = start; i &lt;= end; i++) {
                sum += i;
            }
        } else {
            // 如果任务大于阈值，就分裂成两个子任务计算
            int middle = (start + end) / 2;
            ForkJoinTaskExample leftTask = new ForkJoinTaskExample(start, middle);
            ForkJoinTaskExample rightTask = new ForkJoinTaskExample(middle + 1, end);

            // 执行子任务
            leftTask.fork();
            rightTask.fork();

            // 等待任务执行结束合并其结果
            int leftResult = leftTask.join();
            int rightResult = rightTask.join();

            // 合并子任务
            sum = leftResult + rightResult;
        }
        return sum;
    }

    public static void main(String[] args) {
        ForkJoinPool forkjoinPool = new ForkJoinPool();

        //生成一个计算任务，计算1+2+3+4
        ForkJoinTaskExample task = new ForkJoinTaskExample(1, 100);

        //执行一个任务
        Future&lt;Integer&gt; result = forkjoinPool.submit(task);

        try {
            log.info(&quot;result:{}&quot;, result.get());
        } catch (Exception e) {
            log.error(&quot;exception&quot;, e);
        }
    }
}
</code></pre>
<p><strong>Future</strong></p>
<pre><code>static class MyCallable implements Callable&lt;String&gt; {

        @Override
        public String call() throws Exception {
            log.info(&quot;do something in callable&quot;);
            Thread.sleep(5000);
            return &quot;Done&quot;;
        }
    }

    public static void main(String[] args) throws Exception {
        ExecutorService executorService = Executors.newCachedThreadPool();
        Future&lt;String&gt; future = executorService.submit(new MyCallable());
        log.info(&quot;do something in main&quot;);
        Thread.sleep(1000);
        String result = future.get();
        log.info(&quot;result：{}&quot;, result);
    }
</code></pre>
<p><strong>FutureTask</strong></p>
<pre><code>public static void main(String[] args) throws Exception {
		FutureTask&lt;String&gt; futureTask = new FutureTask&lt;String&gt;(new Callable&lt;String&gt;() {
				@Override
				public String call() throws Exception {
						log.info(&quot;do something in callable&quot;);
						Thread.sleep(5000);
						return &quot;Done&quot;;
				}
		});

		new Thread(futureTask).start();
		log.info(&quot;do something in main&quot;);
		Thread.sleep(1000);
		String result = futureTask.get();
		log.info(&quot;result：{}&quot;, result);
}
</code></pre>
]]></content>
    </entry>
</feed>